{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## setting"],"metadata":{"id":"b_DUal3x__2Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVuwmuJlQMjf"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uk9Wgb4OQMt2"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/python/공공데이터 공모전/data/')\n","import pandas as pd\n","# data path\n","path = '/content/drive/MyDrive/python/공공데이터 공모전/data/'"]},{"cell_type":"code","source":["global_biz = pd.read_json(path+'mapping30.json')\n","hsk_final = pd.read_json(path+'hs_transformer_embedding.json')\n","data = pd.read_excel(path+'비식별된 해외기업별 영문 텍스트데이터.xlsx')\n","global_biz = pd.merge(data, global_biz, on='DSC', how='left')"],"metadata":{"id":"HnZzVDQqX8n-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","import random\n","import tensorflow as tf\n","from tensorflow.keras import layers, Model"],"metadata":{"id":"08WwQswQLO5I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","    except RuntimeError as e:\n","        print(e)"],"metadata":{"id":"yBYNy8G7Ipps"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## VAE recommendation system"],"metadata":{"id":"fYGffO5FBCFF"}},{"cell_type":"code","source":["# Seed 설정\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed = 42\n","set_seed(seed)\n","\n","# 임베딩 값 로드\n","corp_embeddings = np.array(global_biz['transformer_embedding'].tolist())\n","hs_embeddings = np.array(hsk_final['transformer_embedding'].tolist())\n","\n","# 데이터 정규화\n","scaler = StandardScaler()\n","corp_embeddings = scaler.fit_transform(corp_embeddings)\n","hs_embeddings = scaler.fit_transform(hs_embeddings)\n","\n","# 코사인 유사도 계산\n","cosine_similarities = cosine_similarity(corp_embeddings, hs_embeddings)\n","\n","# Improved VAE 모델 정의\n","class ImprovedVAE(nn.Module):\n","    def __init__(self, input_dim, latent_dim):\n","        super(ImprovedVAE, self).__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, 1024),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(1024),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(512),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(256),\n","            nn.Linear(256, latent_dim * 2)  # mu와 logvar\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, 256),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(256),\n","            nn.Linear(256, 512),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(512),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(),\n","            nn.BatchNorm1d(1024),\n","            nn.Linear(1024, input_dim),\n","            nn.Sigmoid()\n","        )\n","\n","    def encode(self, x):\n","        mu_logvar = self.encoder(x)\n","        mu, logvar = mu_logvar.chunk(2, dim=-1)\n","        return mu, logvar\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        recon_x = self.decode(z)\n","        return recon_x, mu, logvar\n","\n","# 손실 함수 정의\n","def vae_loss(recon_x, x, mu, logvar):\n","    MSE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    return MSE + KLD\n","\n","# 하이퍼파라미터 설정\n","input_dim = corp_embeddings.shape[1]\n","latent_dim = 50\n","lr = 1e-4\n","batch_size = 64\n","epochs = 100\n","\n","# 데이터셋 생성\n","corp_embeddings_tensor = torch.tensor(corp_embeddings, dtype=torch.float32)\n","dataset = torch.utils.data.TensorDataset(corp_embeddings_tensor)\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# 모델 초기화\n","vae = ImprovedVAE(input_dim, latent_dim)\n","optimizer = optim.Adam(vae.parameters(), lr=lr)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n","\n","# 모델 학습\n","for epoch in range(epochs):\n","    vae.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        x_batch = batch[0]\n","        optimizer.zero_grad()\n","        recon_x, mu, logvar = vae(x_batch)\n","        loss = vae_loss(recon_x, x_batch, mu, logvar)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    scheduler.step()\n","    avg_loss = total_loss / len(dataloader.dataset)\n","    print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')"],"metadata":{"id":"90nM99IZKBDb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 재구성된 데이터로부터 추천 얻기\n","vae.eval()\n","with torch.no_grad():\n","    reconstructed_data = vae(corp_embeddings_tensor)[0].numpy()\n","\n","# 재구성된 데이터와 HSK 임베딩 간의 유사도 계산\n","reconstructed_similarities = cosine_similarity(reconstructed_data, hs_embeddings)\n","\n","# 상위 10개 유사한 HS 부호 찾기\n","top_n = 10\n","most_similar_indices = np.argsort(-reconstructed_similarities, axis=1)[:, :top_n]\n","\n","# 유사도와 함께 상위 10개 HS 부호 저장\n","top_similarities = np.sort(-reconstructed_similarities, axis=1)[:, :top_n] * -1\n","\n","# VAE_top_10 컬럼에 상위 10개 HS 부호와 유사도 저장\n","vae_top_list = []\n","for row_idx in range(len(global_biz)):\n","    vae_top_dict = {}\n","    for i in range(top_n):\n","        similarity = top_similarities[row_idx][i]\n","        hscode = hsk_final['HS부호'].iloc[int(most_similar_indices[row_idx][i])]\n","        vae_top_dict[str(similarity)] = hscode\n","    vae_top_list.append(vae_top_dict)\n","\n","global_biz['VAE_top_10'] = vae_top_list"],"metadata":{"id":"eGJLNzvoThIL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["global_biz.to_json('VAE.json')"],"metadata":{"id":"y2R1_ik2p9DB"},"execution_count":null,"outputs":[]}]}